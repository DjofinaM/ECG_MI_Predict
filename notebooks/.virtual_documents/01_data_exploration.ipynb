import os
import cv2
import matplotlib.pyplot as plt


DATA_PATH = r"D:\Documents\memoire\realisation\ECG_MI_Predict\data\raw\train"


import numpy as np
from collections import Counter

print("=" * 60)
print("ANALYSE DES TAILLES ET FORMATS D'IMAGES")
print("=" * 60)

# Initialiser les listes pour stocker les informations
image_sizes = []
image_shapes = []
formats_count = {}
problematic_images = []

# Parcourir toutes les images
for cls in classes:
    class_path = os.path.join(DATA_PATH, cls)
    
    for img_name in os.listdir(class_path):
        img_path = os.path.join(DATA_PATH, cls, img_name)
        img = cv2.imread(img_path)
        
        if img is None:
            problematic_images.append((cls, img_name, "Impossible de lire"))
            continue
        
        h, w, c = img.shape
        image_sizes.append((w, h))  # (largeur, hauteur)
        image_shapes.append((h, w, c))
        
        # Format d'image
        _, ext = os.path.splitext(img_name)
        formats_count[ext.lower()] = formats_count.get(ext.lower(), 0) + 1

# Statistiques des tailles
unique_sizes = Counter(image_sizes)
print(f"\nNombre total d'images analysées : {len(image_sizes)}")
print(f"Nombre de tailles différentes : {len(unique_sizes)}")

if len(unique_sizes) <= 10:
    print("\nDétail des tailles d'images :")
    for size, count in unique_sizes.most_common():
        print(f"  {size} : {count} images ({count/len(image_sizes)*100:.1f}%)")
else:
    print(f"\nTop 10 des tailles d'images :")
    for size, count in unique_sizes.most_common(10):
        print(f"  {size} : {count} images ({count/len(image_sizes)*100:.1f}%)")

# Formats d'images
print("\nFormats d'images trouvés :")
for fmt, count in formats_count.items():
    print(f"  {fmt} : {count} images")

# Images problématiques
if problematic_images:
    print(f"\n⚠️  Images problématiques détectées : {len(problematic_images)}")
    for cls, img_name, issue in problematic_images[:3]:
        print(f"  {cls}/{img_name} : {issue}")


for cls in classes:
    class_path = os.path.join(DATA_PATH, cls)
    print(cls, ":", len(os.listdir(class_path)))


cls = classes[0]
img_name = os.listdir(os.path.join(DATA_PATH, cls))[0]

img_path = os.path.join(DATA_PATH, cls, img_name)
img = cv2.imread(img_path)

img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.imshow(img)
plt.title(cls)
plt.axis("off")



import numpy as np
from collections import Counter

print("=" * 60)
print("ANALYSE DES TAILLES ET FORMATS D'IMAGES")
print("=" * 60)

# Initialiser les listes pour stocker les informations
image_sizes = []
image_shapes = []
formats_count = {}
problematic_images = []

# Parcourir toutes les images
for cls in classes:
    class_path = os.path.join(DATA_PATH, cls)
    
    for img_name in os.listdir(class_path):
        img_path = os.path.join(DATA_PATH, cls, img_name)
        img = cv2.imread(img_path)
        
        if img is None:
            problematic_images.append((cls, img_name, "Impossible de lire"))
            continue
        
        h, w, c = img.shape
        image_sizes.append((w, h))  # (largeur, hauteur)
        image_shapes.append((h, w, c))
        
        # Format d'image
        _, ext = os.path.splitext(img_name)
        formats_count[ext.lower()] = formats_count.get(ext.lower(), 0) + 1

# Statistiques des tailles
unique_sizes = Counter(image_sizes)
print(f"\nNombre total d'images analysées : {len(image_sizes)}")
print(f"Nombre de tailles différentes : {len(unique_sizes)}")

if len(unique_sizes) <= 10:
    print("\nDétail des tailles d'images :")
    for size, count in unique_sizes.most_common():
        print(f"  {size} : {count} images ({count/len(image_sizes)*100:.1f}%)")
else:
    print(f"\nTop 10 des tailles d'images :")
    for size, count in unique_sizes.most_common(10):
        print(f"  {size} : {count} images ({count/len(image_sizes)*100:.1f}%)")

# Formats d'images
print("\nFormats d'images trouvés :")
for fmt, count in formats_count.items():
    print(f"  {fmt} : {count} images")

# Images problématiques
if problematic_images:
    print(f"\n⚠️  Images problématiques détectées : {len(problematic_images)}")
    for cls, img_name, issue in problematic_images[:3]:
        print(f"  {cls}/{img_name} : {issue}")


print("\n" + "=" * 60)
print("VISUALISATION ET ANALYSE DE QUALITÉ")
print("=" * 60)

def analyze_image_quality(img):
    """Analyse la qualité d'une image"""
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # Mesures de qualité
    mean_intensity = np.mean(gray)
    std_intensity = np.std(gray)
    
    # Détection des bords pour évaluer la netteté
    edges = cv2.Canny(gray, 100, 200)
    edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
    
    return {
        'mean': mean_intensity,
        'std': std_intensity,
        'edge_density': edge_density
    }

# Analyser un échantillon d'images
n_classes_to_show = min(5, len(classes))
n_images_per_class = 2

fig, axes = plt.subplots(n_images_per_class, n_classes_to_show, 
                         figsize=(4 * n_classes_to_show, 3 * n_images_per_class))

if n_classes_to_show == 1:
    axes = axes.reshape(n_images_per_class, 1)

quality_metrics = []

for col_idx, cls in enumerate(classes[:n_classes_to_show]):
    class_path = os.path.join(DATA_PATH, cls)
    img_names = os.listdir(class_path)[:n_images_per_class]
    
    for row_idx, img_name in enumerate(img_names):
        img_path = os.path.join(DATA_PATH, cls, img_name)
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Analyse de qualité
        metrics = analyze_image_quality(img_rgb)
        metrics['class'] = cls
        quality_metrics.append(metrics)
        
        # Affichage
        ax = axes[row_idx, col_idx]
        ax.imshow(img_rgb)
        ax.set_title(f"{cls}\nMean: {metrics['mean']:.1f}", fontsize=10)
        ax.axis('off')
        
        # Ajouter des informations sur l'image
        h, w, c = img.shape
        ax.text(0.02, 0.98, f"{w}x{h}", 
                transform=ax.transAxes, fontsize=8,
                verticalalignment='top', color='white',
                bbox=dict(boxstyle='round', facecolor='black', alpha=0.5))

plt.suptitle("Échantillon d'images par classe avec métriques de qualité", fontsize=14)
plt.tight_layout()
plt.show()


print("\n" + "=" * 60)
print("VÉRIFICATION DES IMAGES PROBLÉMATIQUES")
print("=" * 60)

problematic_images = []
for cls in classes:
    class_path = os.path.join(DATA_PATH, cls)
    for img_name in os.listdir(class_path):
        img_path = os.path.join(DATA_PATH, cls, img_name)
        img = cv2.imread(img_path)
        
        if img is None:
            problematic_images.append((cls, img_name, "Impossible de lire"))
        elif img.size == 0:
            problematic_images.append((cls, img_name, "Image vide"))

print(f"Images problématiques détectées : {len(problematic_images)}")
if problematic_images:
    print("\nExemples d'images problématiques :")
    for cls, img_name, issue in problematic_images[:5]:
        print(f"  {cls}/{img_name} : {issue}")

print("\n" + "=" * 60)
print("RECOMMANDATIONS POUR LE PRÉTRAITEMENT")
print("=" * 60)

if len(unique_sizes) > 1:
    print("⚠️  Les images ont différentes tailles. Recommandations :")
    print("   1. Redimensionner toutes les images à une taille commune")
    print("   2. Utiliser du padding pour garder les proportions")
else:
    print("✓ Toutes les images ont la même taille")

if len(formats_count) > 1:
    print("⚠️  Formats multiples détectés. Recommandation :")
    print("   Convertir tous en .png pour la consistance")
else:
    print("✓ Format d'image uniforme")

print("\nPour les images ECG, considérez :")
print("   1. Normalisation des intensités (0-255 à 0-1)")
print("   2. Filtrage pour réduire le bruit si nécessaire")
print("   3. Seuillage pour améliorer le contraste")
print("   4. Augmentation de données (rotation, zoom léger)")



